{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1.데이터 다운로드 및 전처리"
      ],
      "metadata": {
        "id": "NqmCnVryBKGj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) pykrx 모듈 다운로드"
      ],
      "metadata": {
        "id": "zD6-Tao0A8yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pykrx"
      ],
      "metadata": {
        "id": "cu5TmDmuvTdv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa57661-9613-4e69-e202-00a5978a664b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pykrx\n",
            "  Downloading pykrx-1.0.45-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pykrx) (2.31.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pykrx) (1.5.3)\n",
            "Collecting datetime (from pykrx)\n",
            "  Downloading DateTime-5.2-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pykrx) (1.23.5)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from pykrx) (2.0.1)\n",
            "Collecting deprecated (from pykrx)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from pykrx) (1.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pykrx) (3.7.1)\n",
            "Collecting zope.interface (from datetime->pykrx)\n",
            "  Downloading zope.interface-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from datetime->pykrx) (2023.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->pykrx) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pykrx) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pykrx) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pykrx) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pykrx) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pykrx) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pykrx) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pykrx) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pykrx) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pykrx) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pykrx) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pykrx) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pykrx) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->pykrx) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.interface->datetime->pykrx) (67.7.2)\n",
            "Installing collected packages: zope.interface, deprecated, datetime, pykrx\n",
            "Successfully installed datetime-5.2 deprecated-1.2.14 pykrx-1.0.45 zope.interface-6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) 데이터 불러오기 (5년 치, 10년 치, 50년 치)"
      ],
      "metadata": {
        "id": "OF5t3JjIBHkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1) 8개 종목 선택\n",
        "\n",
        "KB금융\t105560 신한지주\t055550 하나금융지주\t086790 메리츠금융지주\t138040 기업은행\t024110 미래에셋증권\t006800 NH투자증권\t005940 삼성증권\t016360"
      ],
      "metadata": {
        "id": "gfa7zTwkWMV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make code dictionary.\n",
        "finance_code_dict = dict()\n",
        "finance_code_list = \"KB금융\t105560 신한지주\t055550 하나금융지주\t086790 메리츠금융지주\t138040 기업은행\t024110 미래에셋증권\t006800 NH투자증권\t005940 삼성증권\t016360\".split()\n",
        "for i in range(8):\n",
        "  finance_code_dict[finance_code_list[2*i]] = finance_code_list[2*i + 1]"
      ],
      "metadata": {
        "id": "do3cjAAoBet9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) 데이터 가져오기 함수 정의 (5y, 10y)"
      ],
      "metadata": {
        "id": "cxCbVrCeYeD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pykrx import stock\n",
        "\n",
        "def get_5y_10y(ticker_name):\n",
        "  ticker_code = finance_code_dict[ticker_name]\n",
        "  return stock.get_market_ohlcv(\"20180101\", \"20221231\", ticker_code),\\\n",
        "  stock.get_market_ohlcv(\"20130101\", \"20221231\", ticker_code)"
      ],
      "metadata": {
        "id": "Sn_sJpl5ePvU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (3) 데이터 그리기 함수 정의"
      ],
      "metadata": {
        "id": "DG48bZ0AevsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def draw_graph_10y(ticker_name):\n",
        "\n",
        "  _, df = get_5y_10y(ticker_name)\n",
        "\n",
        "  # 1 line, 3 graphs\n",
        "\n",
        "  # graph 1\n",
        "  plt.subplot(3, 1, 1)\n",
        "  series = df['종가']\n",
        "  plt.title(f\"{ticker_name} time series\")\n",
        "  plt.spring()\n",
        "  plt.plot(series)\n",
        "\n",
        "  # graph 2\n",
        "  plt.subplot(3, 1, 2)\n",
        "  plt.title(f\"{ticker_name} difference, time series\")\n",
        "  series_diff = series - series.shift(1)\n",
        "  plt.plot(series_diff)\n",
        "\n",
        "  # graph 3\n",
        "  plt.subplot(3, 1, 3)\n",
        "  plt.title(f\"{ticker_name} difference, histogram\")\n",
        "  plt.hist(series_diff)\n",
        "\n",
        "  plt.tight_layout()\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "IT7EkiKLey8m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (4) train_data, test_data 얻는 함수"
      ],
      "metadata": {
        "id": "fvftx5hWpKtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_10y_data(ticker_name):\n",
        "  ticker_code = finance_code_dict[ticker_name]\n",
        "  train_df = stock.get_market_ohlcv(\"20130101\", \"20221231\", ticker_code)\n",
        "  test_df = stock.get_market_ohlcv(\"20230101\", \"20230630\", ticker_code)\n",
        "  return train_df['종가'], test_df['종가']"
      ],
      "metadata": {
        "id": "5ekm6NeipKEy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) 데이터 정규화(Normalization)"
      ],
      "metadata": {
        "id": "HdQauhatFBXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) 10y, 10y differencing"
      ],
      "metadata": {
        "id": "SZwcdCpjG4rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for key in finance_code_dict:\n",
        "#   draw_graph_10y(key)"
      ],
      "metadata": {
        "id": "-XGIu8FDgLhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Dataset 윈도우"
      ],
      "metadata": {
        "id": "zzcBKutXIEww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "class windowDataset(Dataset):\n",
        "  # data_stream     : input_window, output_window 크기에 따라 쪼개질 데이터\n",
        "  # input_window    : 인풋 기간\n",
        "  # output_window   : 아웃풋 기간\n",
        "  # stride          :\n",
        "    def __init__(self, data_stream, input_window=80, output_window=20, stride=5):\n",
        "        # data_stream의 행 개수를 구한다.\n",
        "        L = data_stream.shape[0]\n",
        "        # stride에 따라 샘플 개수를 구한다.\n",
        "        num_samples = (L - input_window - output_window) // stride + 1\n",
        "\n",
        "        # [window 크기 * sample 개수] 크기의, 0으로 채워진 배열을 만든다.\n",
        "        X = np.zeros([input_window, num_samples])\n",
        "        Y = np.zeros([output_window, num_samples])\n",
        "\n",
        "        # np.arange(num_samples): range(num_samples) 와 같음\n",
        "        for i in np.arange(num_samples):\n",
        "            # 1) X:   input_window 만큼 자르기 (stride * i ~)\n",
        "            start_x = stride * i\n",
        "            X[:,i] = data_stream[start_x:start_x + input_window]\n",
        "            # 2) Y:   output_window 만큼 자르기 (stride * i + input_window ~)\n",
        "            start_y = start_x + input_window\n",
        "            Y[:,i] = data_stream[start_y:start_y + output_window]\n",
        "\n",
        "\n",
        "        # shape       : [window 크기, sample 개수]\n",
        "        X = X.reshape(X.shape[0], X.shape[1], 1).transpose((1,0,2))\n",
        "        Y = Y.reshape(Y.shape[0], Y.shape[1], 1).transpose((1,0,2))\n",
        "        self.x = X\n",
        "        self.y = Y\n",
        "\n",
        "        self.len = len(X)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.x[i], self.y[i]\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n"
      ],
      "metadata": {
        "id": "dIBH2MZMp3AB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Transformer 모델"
      ],
      "metadata": {
        "id": "as3ta03WIkK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch import nn\n",
        "import torch\n",
        "import math\n",
        "\n",
        "class TFModel(nn.Module):\n",
        "\n",
        "# iw/ow:      input window, output window\n",
        "# d_model:    인풋 개수\n",
        "# nlayers:    인코더 부분의 인코더 개수\n",
        "# nhead:      multihead attention 개수\n",
        "\n",
        "    def __init__(self, iw: int, ow: int, d_model: int, nhead: int, nlayers: int, dropout=0.5):\n",
        "        super(TFModel, self).__init__()\n",
        "\n",
        "        # 1개 인코더, 인풋 사이즈가 d_model이고 attention 개수는 nhead\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout)\n",
        "\n",
        "        # stacked 인코더, nlayers 만큼 쌓여있다.\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=nlayers)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "\n",
        "        # 인풋 차원 변환. 1차원 -> d_model//2차워 -> d_model차원\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(1, d_model//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_model//2, d_model)\n",
        "        )\n",
        "\n",
        "        # 차원 변환. d_model -> d_model//2 -> 1\n",
        "        self.linear =  nn.Sequential(\n",
        "            nn.Linear(d_model, d_model//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_model//2, 1)\n",
        "        )\n",
        "\n",
        "        # 차원 변환. iw -> ow\n",
        "        self.linear2 = nn.Sequential(\n",
        "            nn.Linear(iw, (iw+ow)//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear((iw+ow)//2, ow)\n",
        "        )\n",
        "\n",
        "    def generate_square_subsequent_mask(self, size):\n",
        "        mask = (torch.triu(torch.ones(size, size)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def forward(self, src, srcmask):\n",
        "        src = self.encoder(src)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src.transpose(0,1), srcmask).transpose(0,1)\n",
        "        output = self.linear(output)[:,:,0]\n",
        "        output = self.linear2(output)\n",
        "        return output\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "def gen_attention_mask(x):\n",
        "    mask = torch.eq(x, 0)\n",
        "    return mask\n"
      ],
      "metadata": {
        "id": "rPshqZFbp86W"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.학습"
      ],
      "metadata": {
        "id": "nEvoEQehIpqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 입출력 윈도우 사이즈\n",
        "- Learning Rate\n",
        "- Model\n",
        "  - layer\n",
        "  - dropout\n",
        "  - multihead attention 개수\n",
        "- Cost Function\n",
        "- Optimizer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YmQeCcBoN8fI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Hyper-parameter\n",
        "INPUT_WINDOW = 21*14\n",
        "OUTPUT_WINDOW = 4Model\n",
        "layer\n",
        "dropout\n",
        "multihead attention 개수\n",
        "Cost Function\n",
        "Optimizer\n",
        "Hyper-parameter\n",
        "\n",
        "train_data, test_data = get_10y_data('KB금융')\n",
        "train_dataset = windowDataset(train_data, input_window=INPUT_WINDOW, output_window=OUTPUT_WINDOW, stride=1)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64)     # 64 = 2^6, 512 = 2^9\n",
        "test_dataset = windowDataset(train_data, input_window=INPUT_WINDOW, output_window=OUTPUT_WINDOW, stride=1)\n",
        "test_loader = DataLoader(train_dataset, batch_size=64)     # 64 = 2^6, 512 = 2^9\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "lr = 1e-4\n",
        "model = TFModel(iw=INPUT_WINDOW, ow=OUTPUT_WINDOW, d_model=512, nhead=8, nlayers=4, dropout=0.1).to(device)\n",
        "criterion = nn.MSELoss()                                            # MSEloss(): ow 각 요소들의 합\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "Y74qg9doJU5X",
        "cellView": "form"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Train\n",
        "'''\n",
        "[error]\n",
        "OutOfMemoryError: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 14.75 GiB total capacity; 13.76 GiB already allocated; 70.81 MiB free; 13.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
        "\n",
        "[solution]\n",
        "https://discuss.pytorch.kr/t/cuda-out-of-memory/216/6\n",
        "'''\n",
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# for tqdm\n",
        "from tqdm import tqdm\n",
        "epoch = 30\n",
        "model.train()\n",
        "progress = tqdm(range(epoch))\n",
        "\n",
        "for i in progress:\n",
        "  batchloss = 0.0\n",
        "  for (inputs, outputs) in train_loader:\n",
        "    # inputs.shape: [batch_size, iw, 1]\n",
        "    # outputs.shape: [batch_size, ow, 1]\n",
        "\n",
        "    # Initialize grad\n",
        "    optimizer.zero_grad()                                           # zero_grad()로 Torch.Tensor.grad 초기화. 초기화하지 않으면 다음 루프 backward() 시에 간섭함.\n",
        "\n",
        "    # Forward propagation with masking\n",
        "    src_mask = model.generate_square_subsequent_mask(inputs.shape[1]).to(device)\n",
        "    result = model(inputs.float().to(device), src_mask)             # forward\n",
        "\n",
        "    # Backward propagation\n",
        "    loss = criterion(result, outputs[:,:,0].float().to(device))     # ?? 64개 중 하나만 loss를 담네?\n",
        "    loss.backward()                                                 # backward\n",
        "    optimizer.step()\n",
        "    batchloss += loss\n",
        "\n",
        "  print()\n",
        "  progress.set_description(f\"loss: {batchloss.cpu().item() / len(train_loader):0.6f}\")\n",
        "\n",
        "progress.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NnYlIderGyS",
        "outputId": "a77ad70e-8fcb-40c4-adb1-3302bfb24aaa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/30 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 2169968278.588235:   3%|▎         | 1/30 [00:24<11:48, 24.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 2167077707.294117:   7%|▋         | 2/30 [00:44<10:11, 21.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 2156706394.352941:  10%|█         | 3/30 [01:03<09:15, 20.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 2128638674.823529:  13%|█▎        | 4/30 [01:22<08:39, 19.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 2066684024.470588:  17%|█▋        | 5/30 [01:42<08:16, 19.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 1949760813.176471:  20%|██        | 6/30 [02:01<07:55, 19.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 1756526351.058824:  23%|██▎       | 7/30 [02:21<07:32, 19.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 1474722032.941176:  27%|██▋       | 8/30 [02:40<07:09, 19.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 1116411904.000000:  30%|███       | 9/30 [03:00<06:49, 19.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 730937524.705882:  33%|███▎      | 10/30 [03:19<06:30, 19.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 400166881.882353:  37%|███▋      | 11/30 [03:39<06:10, 19.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 193510580.705882:  40%|████      | 12/30 [03:58<05:50, 19.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 118668769.882353:  43%|████▎     | 13/30 [04:17<05:30, 19.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 121466910.117647:  47%|████▋     | 14/30 [04:37<05:10, 19.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 108003998.117647:  50%|█████     | 15/30 [04:56<04:51, 19.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 91648293.647059:  53%|█████▎    | 16/30 [05:15<04:31, 19.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 89271612.235294:  57%|█████▋    | 17/30 [05:35<04:11, 19.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 87791992.470588:  60%|██████    | 18/30 [05:54<03:52, 19.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 86978288.941176:  63%|██████▎   | 19/30 [06:13<03:32, 19.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 86509884.235294:  67%|██████▋   | 20/30 [06:33<03:13, 19.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 86207616.000000:  70%|███████   | 21/30 [06:52<02:54, 19.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 86015909.647059:  73%|███████▎  | 22/30 [07:12<02:35, 19.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 85889792.000000:  77%|███████▋  | 23/30 [07:31<02:15, 19.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 85817404.235294:  80%|████████  | 24/30 [07:51<01:56, 19.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 85738985.411765:  83%|████████▎ | 25/30 [08:10<01:37, 19.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 85715034.352941:  87%|████████▋ | 26/30 [08:30<01:17, 19.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 85695397.647059:  90%|█████████ | 27/30 [08:49<00:58, 19.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 85687017.411765:  93%|█████████▎| 28/30 [09:09<00:38, 19.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 85665031.529412:  97%|█████████▋| 29/30 [09:28<00:19, 19.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 85668171.294118: 100%|██████████| 30/30 [09:48<00:00, 19.60s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Test"
      ],
      "metadata": {
        "id": "EIU5cu4p-LbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize correct & total\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# 기울기 계산을 방지하기 위해 torch.no_grad() 블록 안에서 평가\n",
        "with torch.no_grad():\n",
        "  for (inputs, outputs) in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "    # Forward propagation with masking\n",
        "    src_mask = model.generate_square_subsequent_mask(inputs.shape[1]).to(device)\n",
        "    result = model(inputs.float().to(device), src_mask)\n",
        "\n",
        "    # 상승/하강 예측\n",
        "    predicted_changes = torch.sign(result[:, -1] - inputs[:, -1, 0].to(device))             # 마지막 예측 값 - 마지막 입력 값\n",
        "    true_changes = torch.sign(outputs[:, -1, 0].to(device) - inputs[:, -1, 0].to(device))  # 실제 마지막 값 - 마지막 입력 값\n",
        "\n",
        "    # 예측이 맞는 경우\n",
        "    correct += (predicted_changes == true_changes).sum().item()\n",
        "    total += inputs.size(0)\n",
        "\n",
        "  print()\n",
        "  progress.set_description(f\"current accuracy: {correct/total:0.6f}\")\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = correct / total\n",
        "print(f\"\\nDirectional Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "5iM3ACWWurGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b818547-42a4-4515-da8f-6b6ffa20017d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 34/34 [00:05<00:00,  5.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Directional Accuracy: 0.1899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}